{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-qSSzXu6sNOP",
        "outputId": "3f901b20-669f-4157-9d81-4af78a980231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Exploring-Mental-Health-Data'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 42 (delta 11), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (42/42), 5.49 MiB | 3.78 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "/content/Exploring-Mental-Health-Data/Exploring-Mental-Health-Data\n"
          ]
        }
      ],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/geopan2000/Exploring-Mental-Health-Data.git\n",
        "\n",
        "# Change directory to the cloned repository\n",
        "%cd Exploring-Mental-Health-Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "!pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "!pip install scikit-optimize\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "xy-6SSxfCTjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c00e3b-efbb-478d-f482-9fac631d1d75"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = pd.read_csv('/content/Exploring-Mental-Health-Data/data/train.csv')\n",
        "test_set = pd.read_csv('/content/Exploring-Mental-Health-Data/data/test.csv')"
      ],
      "metadata": {
        "id": "yh9AABJ5CX0f"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.head()"
      ],
      "metadata": {
        "id": "UQzDBpoXCip3",
        "outputId": "136a6a37-d109-4670-a40d-4d0375a82bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id      Name  Gender   Age           City Working Professional or Student  \\\n",
              "0   0  Aaradhya  Female  49.0       Ludhiana            Working Professional   \n",
              "1   1     Vivan    Male  26.0       Varanasi            Working Professional   \n",
              "2   2    Yuvraj    Male  33.0  Visakhapatnam                         Student   \n",
              "3   3    Yuvraj    Male  22.0         Mumbai            Working Professional   \n",
              "4   4      Rhea  Female  30.0         Kanpur            Working Professional   \n",
              "\n",
              "         Profession  Academic Pressure  Work Pressure  CGPA  \\\n",
              "0              Chef                NaN            5.0   NaN   \n",
              "1           Teacher                NaN            4.0   NaN   \n",
              "2               NaN                5.0            NaN  8.97   \n",
              "3           Teacher                NaN            5.0   NaN   \n",
              "4  Business Analyst                NaN            1.0   NaN   \n",
              "\n",
              "   Study Satisfaction  Job Satisfaction     Sleep Duration Dietary Habits  \\\n",
              "0                 NaN               2.0  More than 8 hours        Healthy   \n",
              "1                 NaN               3.0  Less than 5 hours      Unhealthy   \n",
              "2                 2.0               NaN          5-6 hours        Healthy   \n",
              "3                 NaN               1.0  Less than 5 hours       Moderate   \n",
              "4                 NaN               1.0          5-6 hours      Unhealthy   \n",
              "\n",
              "    Degree Have you ever had suicidal thoughts ?  Work/Study Hours  \\\n",
              "0      BHM                                    No               1.0   \n",
              "1      LLB                                   Yes               7.0   \n",
              "2  B.Pharm                                   Yes               3.0   \n",
              "3      BBA                                   Yes              10.0   \n",
              "4      BBA                                   Yes               9.0   \n",
              "\n",
              "   Financial Stress Family History of Mental Illness  Depression  \n",
              "0               2.0                               No           0  \n",
              "1               3.0                               No           1  \n",
              "2               1.0                               No           1  \n",
              "3               1.0                              Yes           1  \n",
              "4               4.0                              Yes           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27718f5b-a309-420e-b0be-cae12fdc7e73\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>City</th>\n",
              "      <th>Working Professional or Student</th>\n",
              "      <th>Profession</th>\n",
              "      <th>Academic Pressure</th>\n",
              "      <th>Work Pressure</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Study Satisfaction</th>\n",
              "      <th>Job Satisfaction</th>\n",
              "      <th>Sleep Duration</th>\n",
              "      <th>Dietary Habits</th>\n",
              "      <th>Degree</th>\n",
              "      <th>Have you ever had suicidal thoughts ?</th>\n",
              "      <th>Work/Study Hours</th>\n",
              "      <th>Financial Stress</th>\n",
              "      <th>Family History of Mental Illness</th>\n",
              "      <th>Depression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Aaradhya</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Ludhiana</td>\n",
              "      <td>Working Professional</td>\n",
              "      <td>Chef</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>More than 8 hours</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>BHM</td>\n",
              "      <td>No</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vivan</td>\n",
              "      <td>Male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>Varanasi</td>\n",
              "      <td>Working Professional</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Less than 5 hours</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>LLB</td>\n",
              "      <td>Yes</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Yuvraj</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>Visakhapatnam</td>\n",
              "      <td>Student</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.97</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5-6 hours</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>B.Pharm</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Yuvraj</td>\n",
              "      <td>Male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Working Professional</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Less than 5 hours</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>BBA</td>\n",
              "      <td>Yes</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Rhea</td>\n",
              "      <td>Female</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Kanpur</td>\n",
              "      <td>Working Professional</td>\n",
              "      <td>Business Analyst</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5-6 hours</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>BBA</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27718f5b-a309-420e-b0be-cae12fdc7e73')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27718f5b-a309-420e-b0be-cae12fdc7e73 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27718f5b-a309-420e-b0be-cae12fdc7e73');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d898a183-e0df-49ab-9877-27bfaf36fb8f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d898a183-e0df-49ab-9877-27bfaf36fb8f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d898a183-e0df-49ab-9877-27bfaf36fb8f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_set"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Inspection"
      ],
      "metadata": {
        "id": "g7oFrxdGWvhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train_print = train_set.copy()\n",
        "#train_print = train_print.drop(columns=['Depression'])\n",
        "\n",
        "#for column in train_print.columns:\n",
        "    #train_nan_ratio = train_print[column].isna().sum() / len(train_print)  # Proportion of NaN in train set\n",
        "    #test_nan_ratio = test_set[column].isna().sum() / len(test_set)  # Proportion of NaN in test set\n",
        "    #print(f\"{column}  Train Set: {train_nan_ratio:.2%} Test Set: {test_nan_ratio:.2%}\")"
      ],
      "metadata": {
        "id": "KhM0uFVhZF9l"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the value counts for train and test sets\n",
        "#train_counts = train_set['Profession'].value_counts()\n",
        "#test_counts = test_set['Profession'].value_counts()\n",
        "\n",
        "# Get a combined set of unique values from both train and test sets\n",
        "#all_professions = set(train_counts.index).union(set(test_counts.index))\n",
        "\n",
        "# Print the counts for each profession\n",
        "#for profession in all_professions:\n",
        " #   train_count = train_counts.get(profession, 0)  # Get count from train, default to 0\n",
        "  #  test_count = test_counts.get(profession, 0)   # Get count from test, default to 0\n",
        "   # print(f\"{profession}: Train_set={train_count} Test_set={test_count}\")"
      ],
      "metadata": {
        "id": "uNd2rFkFcDAa"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering:\n"
      ],
      "metadata": {
        "id": "qm9h56dJLbEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_id = train_set['id']\n",
        "\n",
        "target_variable = train_set['Depression']\n",
        "train_set.drop(columns=['Name','Depression'], inplace=True)\n",
        "test_id = test_set['id']\n",
        "\n",
        "test_set.drop(columns=['Name'], inplace=True)\n",
        "\n",
        "train_set['Gender'] = train_set['Gender'].map({'Male' : 1, 'Female' : 0}) # Always trasnforming 2 option object types into binary\n",
        "test_set['Gender'] = test_set['Gender'].map({'Male' : 1, 'Female' : 0})\n",
        "\n",
        "train_set['Age'] = train_set['Age'] / 100 # Normalized by the Max value\n",
        "train_set['Age'] = train_set['Age'].fillna(train_set['Age'].mean())\n",
        "test_set['Age'] = test_set['Age'] / 100\n",
        "test_set['Age'] = test_set['Age'].fillna(test_set['Age'].mean())\n",
        "\n",
        "train_set['Working Professional or Student'] = train_set['Working Professional or Student'].map({'Working Professional' : 1, 'Student' : 0}) # Always trasnforming 2 option object types into binary\n",
        "test_set['Working Professional or Student'] = test_set['Working Professional or Student'].map({'Working Professional' : 1, 'Student' : 0})\n",
        "\n",
        "train_set['CGPA'] = train_set['CGPA'] /10\n",
        "train_set['CGPA'] = train_set['CGPA'].fillna(0)\n",
        "test_set['CGPA'] = test_set['CGPA'] /10\n",
        "test_set['CGPA'] = test_set['CGPA'].fillna(0)\n",
        "\n",
        "train_set['Have you ever had suicidal thoughts ?'] = train_set['Have you ever had suicidal thoughts ?'].map({'Yes' : 1, 'No' : 0}) # Always trasnforming 2 option object types into binary\n",
        "test_set['Have you ever had suicidal thoughts ?'] = test_set['Have you ever had suicidal thoughts ?'].map({'Yes' : 1, 'No' : 0})\n",
        "\n",
        "train_set['Work/Study Hours'] = train_set['Work/Study Hours'] / 24 # Normalized by the Max value\n",
        "test_set['Work/Study Hours'] = test_set['Work/Study Hours'] / 24\n",
        "\n",
        "train_set['Financial Stress'] = train_set['Financial Stress'] / 5 # Normalized by the Max value\n",
        "train_set['Financial Stress'] = train_set['Financial Stress'].fillna(0)\n",
        "test_set['Financial Stress'] = test_set['Financial Stress'] / 5\n",
        "test_set['Financial Stress'] = test_set['Financial Stress'].fillna(0)\n",
        "\n",
        "train_set['Family History of Mental Illness'] = train_set['Family History of Mental Illness'].map({'Yes' : 1, 'No' : 0}) # Always trasnforming 2 option object types into binary\n",
        "test_set['Family History of Mental Illness'] = test_set['Family History of Mental Illness'].map({'Yes' : 1, 'No' : 0})"
      ],
      "metadata": {
        "id": "9DqcZW0JLXRz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new feature 'Academic/Work Pressure'\n",
        "train_set['Academic/Work Pressure'] = train_set.apply(\n",
        "    lambda row: row['Academic Pressure'] if pd.notna(row['Academic Pressure']) and pd.isna(row['Work Pressure']) else\n",
        "                row['Work Pressure'] if pd.isna(row['Academic Pressure']) and pd.notna(row['Work Pressure']) else\n",
        "                (row['Academic Pressure'] + row['Work Pressure']) / 2 if pd.notna(row['Academic Pressure']) and pd.notna(row['Work Pressure']) else\n",
        "                None,  # Placeholder for rows where both are NaN\n",
        "    axis=1)\n",
        "\n",
        "# Fill any remaining NaN in 'Academic/Work Pressure' with its mean\n",
        "train_set['Academic/Work Pressure'] = train_set['Academic/Work Pressure'].fillna(train_set['Academic/Work Pressure'].mean())\n",
        "\n",
        "train_set['Academic Pressure'] = train_set['Academic Pressure'] / 5\n",
        "train_set['Academic Pressure'] = train_set['Academic Pressure'].fillna(0)\n",
        "\n",
        "train_set['Work Pressure'] = train_set['Work Pressure'] / 5\n",
        "train_set['Work Pressure'] = train_set['Work Pressure'].fillna(0)"
      ],
      "metadata": {
        "id": "nsrLzYkZNrf8"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new feature 'Academic/Work Pressure'\n",
        "test_set['Academic/Work Pressure'] = test_set.apply(\n",
        "    lambda row: row['Academic Pressure'] if pd.notna(row['Academic Pressure']) and pd.isna(row['Work Pressure']) else\n",
        "                row['Work Pressure'] if pd.isna(row['Academic Pressure']) and pd.notna(row['Work Pressure']) else\n",
        "                (row['Academic Pressure'] + row['Work Pressure']) / 2 if pd.notna(row['Academic Pressure']) and pd.notna(row['Work Pressure']) else\n",
        "                None,  # Placeholder for rows where both are NaN\n",
        "    axis=1)\n",
        "\n",
        "# Fill any remaining NaN in 'Academic/Work Pressure' with its mean\n",
        "test_set['Academic/Work Pressure'] = test_set['Academic/Work Pressure'].fillna(test_set['Academic/Work Pressure'].mean())\n",
        "\n",
        "test_set['Academic Pressure'] = test_set['Academic Pressure'] / 5\n",
        "test_set['Academic Pressure'] = test_set['Academic Pressure'].fillna(0)\n",
        "\n",
        "test_set['Work Pressure'] = test_set['Work Pressure'] / 5\n",
        "test_set['Work Pressure'] = test_set['Work Pressure'].fillna(0)"
      ],
      "metadata": {
        "id": "NlJKv80WnYZ3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new feature Study/Job Satisfaction\n",
        "train_set['Study/Job Satisfaction'] = train_set.apply(\n",
        "    lambda row: row['Study Satisfaction'] if pd.notna(row['Study Satisfaction']) and pd.isna(row['Job Satisfaction']) else\n",
        "                row['Job Satisfaction'] if pd.isna(row['Study Satisfaction']) and pd.notna(row['Job Satisfaction']) else\n",
        "                (row['Study Satisfaction'] + row['Job Satisfaction']) / 2 if pd.notna(row['Study Satisfaction']) and pd.notna(row['Job Satisfaction']) else\n",
        "                None,  # Placeholder for rows where both are NaN\n",
        "    axis=1)\n",
        "\n",
        "# Fill any remaining NaN in Study/Job Satisfaction with its mean\n",
        "train_set['Study/Job Satisfaction'] = train_set['Study/Job Satisfaction'].fillna(train_set['Study/Job Satisfaction'].mean())\n",
        "\n",
        "train_set['Study Satisfaction'] = train_set['Study Satisfaction'] / 5\n",
        "train_set['Study Satisfaction'] = train_set['Study Satisfaction'].fillna(0)\n",
        "\n",
        "train_set['Job Satisfaction'] = train_set['Job Satisfaction'] / 5\n",
        "train_set['Job Satisfaction'] = train_set['Job Satisfaction'].fillna(0)"
      ],
      "metadata": {
        "id": "RLBK-FG1Ny4C"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new feature Study/Job Satisfaction\n",
        "test_set['Study/Job Satisfaction'] = test_set.apply(\n",
        "    lambda row: row['Study Satisfaction'] if pd.notna(row['Study Satisfaction']) and pd.isna(row['Job Satisfaction']) else\n",
        "                row['Job Satisfaction'] if pd.isna(row['Study Satisfaction']) and pd.notna(row['Job Satisfaction']) else\n",
        "                (row['Study Satisfaction'] + row['Job Satisfaction']) / 2 if pd.notna(row['Study Satisfaction']) and pd.notna(row['Job Satisfaction']) else\n",
        "                None,  # Placeholder for rows where both are NaN\n",
        "    axis=1)\n",
        "\n",
        "# Fill any remaining NaN in Study/Job Satisfaction with its mean\n",
        "test_set['Study/Job Satisfaction'] = test_set['Study/Job Satisfaction'].fillna(test_set['Study/Job Satisfaction'].mean())\n",
        "\n",
        "test_set['Study Satisfaction'] = test_set['Study Satisfaction'] / 5\n",
        "test_set['Study Satisfaction'] = test_set['Study Satisfaction'].fillna(0)\n",
        "\n",
        "test_set['Job Satisfaction'] = test_set['Job Satisfaction'] / 5\n",
        "test_set['Job Satisfaction'] = test_set['Job Satisfaction'].fillna(0)"
      ],
      "metadata": {
        "id": "8cEjqk0dnhQd"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and test value counts\n",
        "train_counts = train_set['City'].value_counts()\n",
        "test_counts = test_set['City'].value_counts()\n",
        "\n",
        "# Create a combined count of professions\n",
        "combined_counts = train_counts.add(test_counts, fill_value=0)\n",
        "\n",
        "# Identify professions appearing less than 5 times in either set\n",
        "low_frequency_values = combined_counts[combined_counts < 10].index.tolist()\n",
        "\n",
        "# Map low-frequency values to 'None' in both train and test sets\n",
        "train_set['City'] = train_set['City'].apply(lambda x: 'Other' if x in low_frequency_values else x)\n",
        "test_set['City'] = test_set['City'].apply(lambda x: 'Other' if x in low_frequency_values else x)"
      ],
      "metadata": {
        "id": "WBJlJvkDQNkT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and test value counts\n",
        "train_counts = train_set['Profession'].value_counts()\n",
        "test_counts = test_set['Profession'].value_counts()\n",
        "\n",
        "# Create a combined count of professions\n",
        "combined_counts = train_counts.add(test_counts, fill_value=0)\n",
        "\n",
        "# Identify professions appearing less than 5 times in either set\n",
        "low_frequency_values = combined_counts[combined_counts < 10].index.tolist()\n",
        "\n",
        "# Map low-frequency values to 'None' in both train and test sets\n",
        "train_set['Profession'] = train_set['Profession'].apply(lambda x: 'Other' if x in low_frequency_values else x)\n",
        "test_set['Profession'] = test_set['Profession'].apply(lambda x: 'Other' if x in low_frequency_values else x)"
      ],
      "metadata": {
        "id": "jtPh01G6P8IL"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and test value counts\n",
        "train_counts = train_set['Degree'].value_counts()\n",
        "test_counts = test_set['Degree'].value_counts()\n",
        "\n",
        "# Create a combined count of professions\n",
        "combined_counts = train_counts.add(test_counts, fill_value=0)\n",
        "\n",
        "# Identify professions appearing less than 5 times in either set\n",
        "low_frequency_values = combined_counts[combined_counts < 10].index.tolist()\n",
        "\n",
        "# Map low-frequency values to 'None' in both train and test sets\n",
        "train_set['Degree'] = train_set['Degree'].apply(lambda x: 'Other' if x in low_frequency_values else x)\n",
        "test_set['Degree'] = test_set['Degree'].apply(lambda x: 'Other' if x in low_frequency_values else x)"
      ],
      "metadata": {
        "id": "SXwCvPvIQdpq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set['City'] = train_set['City'].fillna('X')\n",
        "freq = train_set['City'].value_counts()\n",
        "train_set['City_freq'] = train_set['City'].map(freq) # Frequency encoding different cities\n",
        "\n",
        "test_set['City'] = test_set['City'].fillna('X')\n",
        "test_set['City_freq'] = test_set['City'].map(freq) # Frequency encoding different cities\n",
        "\n",
        "\n",
        "train_set['Degree'] = train_set['Degree'].fillna('X')\n",
        "freq = train_set['Degree'].value_counts()\n",
        "train_set['Degree_freq'] = train_set['Degree'].map(freq) # Frequency encoding\n",
        "\n",
        "test_set['Degree'] = test_set['Degree'].fillna('X')\n",
        "test_set['Degree_freq'] = test_set['Degree'].map(freq) # Frequency encoding\n",
        "\n",
        "\n",
        "train_set['Profession'] = train_set['Profession'].fillna('X')\n",
        "freq = train_set['Profession'].value_counts()\n",
        "train_set['Profession_freq'] = train_set['Profession'].map(freq) # Frequency encoding\n",
        "\n",
        "test_set['Profession'] = test_set['Profession'].fillna('X')\n",
        "test_set['Profession_freq'] = test_set['Profession'].map(freq) # Frequency encoding"
      ],
      "metadata": {
        "id": "bm168rqvSxtd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the original number of rows for splitting later\n",
        "train_size = len(train_set)\n",
        "\n",
        "# Concatenate train and test sets\n",
        "concat_set = pd.concat([train_set, test_set], axis=0)\n",
        "\n",
        "# Apply one-hot encoding to the concatenated set\n",
        "concat_set = pd.get_dummies(concat_set, columns=['Degree', 'Profession', 'City'])\n",
        "\n",
        "# Split the concatenated set back into train and test sets\n",
        "train_set = concat_set.iloc[:train_size, :].copy()  # Get the original train rows\n",
        "test_set = concat_set.iloc[train_size:, :].copy()   # Get the original test rows\n",
        "\n",
        "print(\"Train set shape:\", train_set.shape)\n",
        "print(\"Test set shape:\", test_set.shape)"
      ],
      "metadata": {
        "id": "mdoyvMXlhcZn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8280d712-e5c0-4782-a1fe-139d39602ccb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (140700, 119)\n",
            "Test set shape: (93800, 119)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Define a function to encode Sleep Duration\n",
        "def encode_sleep_duration(value):\n",
        "    # Check for NaN or None\n",
        "    if pd.isna(value):\n",
        "        return -1  # Placeholder for missing or invalid values\n",
        "\n",
        "    # Ensure the value is a string\n",
        "    value = str(value).strip()\n",
        "\n",
        "    # Encoding logic\n",
        "    if 'Less than 5 hours' in value or value in ['3-4 hours', '4-5 hours', '2-3 hours']:\n",
        "        return 1  # < 5 hours\n",
        "    elif '5-6 hours' in value:\n",
        "        return 2  # 5-6 hours\n",
        "    elif '6-7 hours' in value or '6-8 hours' in value:\n",
        "        return 3  # 6-7 hours\n",
        "    elif '7-8 hours' in value:\n",
        "        return 4  # 7-8 hours\n",
        "    elif 'More than 8 hours' in value or '8-9 hours' in value or '9-11 hours' in value:\n",
        "        return 5  # > 8 hours\n",
        "    else:\n",
        "        return -1  # Placeholder for other invalid or unclear values\n",
        "\n",
        "sleep_mapping = {\n",
        "    'More than 8 hours': '>8',\n",
        "    'Less than 5 hours': '<5',\n",
        "    'Moderate': '5-6 hours',\n",
        "    '9-6 hours': '6-9 hours',\n",
        "\n",
        "    '10-6 hours': '6-10 hours',\n",
        "    'than 5 hours': '4-6 hours',\n",
        "    'Unhealthy': '4-6 hours',\n",
        "    '9-5 hours': '5-9 hours',\n",
        "    '9-5': '5-9 hours',\n",
        "    '8-89 hours': '8-9 hours',\n",
        "\n",
        "    # Ambiguous or irrelevant entries\n",
        "    'Sleep_Duration': None, '40-45 hours': None, '55-66 hours': None, 'Indore': None,\n",
        "    '45': None, '35-36 hours': None, 'No': None, 'Indore': None, '49 hours': None,\n",
        "    'Work_Study_Hours': None, '45-48 hours': None, 'Pune': None, 'Soham': None,\n",
        "    '0': None, 'Meerut': None, '60-65 hours': None, 'Vivan': None,\n",
        "    'Have_you_ever_had_suicidal_thoughts': None, '20-21 hours': None, '50-75 hours': None\n",
        "}\n",
        "\n",
        "# Define range extraction function\n",
        "def extract_range(value):\n",
        "    try:\n",
        "        if '-' in value:\n",
        "            parts = value.split('-')\n",
        "            return int(parts[0]), int(parts[1].split()[0])\n",
        "        elif '<' in value:\n",
        "            return 3, 5\n",
        "        elif '>' in value:\n",
        "            lower_bound = int(value.split('>')[1].split()[0])\n",
        "            return lower_bound, 10\n",
        "        elif value.isdigit():\n",
        "            num = int(value)\n",
        "            return num, num\n",
        "        else:\n",
        "            return None, None\n",
        "    except:\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "Kv_Tsp9Gxkl9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set['Sleep Duration'] = train_set['Sleep Duration'].map(sleep_mapping)\n",
        "test_set['Sleep Duration'] = test_set['Sleep Duration'].map(sleep_mapping)\n",
        "\n",
        "train_set['Sleep_Duration_Encoded'] = train_set['Sleep Duration'].apply(encode_sleep_duration)\n",
        "test_set['Sleep_Duration_Encoded'] = test_set['Sleep Duration'].apply(encode_sleep_duration)\n",
        "\n",
        "# Apply the function to create 'From' and 'To' columns\n",
        "train_set[['From', 'To']] = train_set['Sleep Duration'].apply(lambda x: pd.Series(extract_range(x)))\n",
        "test_set[['From', 'To']] = test_set['Sleep Duration'].apply(lambda x: pd.Series(extract_range(x)))\n",
        "\n",
        "# Handle missing values\n",
        "train_set['From'] = train_set['From'].fillna(train_set['From'].mean())\n",
        "train_set['To'] = train_set['To'].fillna(train_set['To'].mean())\n",
        "\n",
        "test_set['From'] = test_set['From'].fillna(test_set['From'].mean())\n",
        "test_set['To'] = test_set['To'].fillna(test_set['To'].mean())\n",
        "\n",
        "# Drop the original column if not needed\n",
        "train_set.drop(columns=['Sleep Duration'], inplace=True)\n",
        "test_set.drop(columns=['Sleep Duration'], inplace=True)"
      ],
      "metadata": {
        "id": "l9dczY77kt9q"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train set shape:\", train_set.shape)\n",
        "print(\"Test set shape:\", test_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDylv8whlYyB",
        "outputId": "d3619846-ee0c-4b42-ce86-dc07dbc1794d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (140700, 121)\n",
            "Test set shape: (93800, 121)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define mapping for valid dietary habits\n",
        "dietary_mapping = {\n",
        "    'Moderate': 'Moderate',\n",
        "    'Unhealthy': 'Unhealthy',\n",
        "    'Healthy': 'Healthy',\n",
        "    'More Healthy': 'Healthy',\n",
        "    'Less Healthy': 'Unhealthy',\n",
        "    'Less than Healthy': 'Unhealthy',\n",
        "    'No Healthy': 'Unhealthy',\n",
        "    '3': 'Moderate',\n",
        "    '1.0': 'Unhealthy',\n",
        "    '2': 'Moderate',\n",
        "    '5 Healthy': 'Healthy',\n",
        "    '5 Unhealthy': 'Unhealthy',\n",
        "\n",
        "    # Ambiguous or irrelevant entries\n",
        "    'Yes': None, 'No': None, 'No Healthy': None, 'Class 12': None, 'Indoor': None,\n",
        "    'Male': None, 'Vegas': None, 'M.Tech': None, 'Electrician': None,\n",
        "    'Hormonal': None, 'Mihir': None, 'Gender': None, 'BSc': None,\n",
        "    'Pratham': None, 'Prachi': None, 'Resistant': None, 'Mealy': None,\n",
        "\n",
        "    'nan': None, 'Academic': None, 'Educational': None, 'Soham': None,\n",
        "    'Naina': None, 'Kolkata': None, 'Raghav': None, 'Vivaan': None,  'MCA': None,\n",
        "}\n",
        "\n",
        "# Apply the mapping to the Dietary Habits column\n",
        "train_set['Dietary Habits'] = train_set['Dietary Habits'].map(dietary_mapping)\n",
        "train_set['Dietary Habits'] = train_set['Dietary Habits'].fillna('X')\n",
        "\n",
        "test_set['Dietary Habits'] = test_set['Dietary Habits'].map(dietary_mapping)\n",
        "test_set['Dietary Habits'] = test_set['Dietary Habits'].fillna('X')\n",
        "\n",
        "freq = train_set['Dietary Habits'].value_counts()\n",
        "train_set['Dietary Habits_freq'] = train_set['Dietary Habits'].map(freq) # frequency encoding\n",
        "test_set['Dietary Habits_freq'] = test_set['Dietary Habits'].map(freq) # frequency encoding\n",
        "\n",
        "# Save the original number of rows for splitting later\n",
        "train_size = len(train_set)\n",
        "\n",
        "# Concatenate train and test sets\n",
        "concat_set = pd.concat([train_set, test_set], axis=0)\n",
        "\n",
        "# Apply one-hot encoding to the concatenated set\n",
        "concat_set = pd.get_dummies(concat_set, columns=['Dietary Habits'])\n",
        "\n",
        "# Split the concatenated set back into train and test sets\n",
        "train_set = concat_set.iloc[:train_size, :].copy()  # Get the original train rows\n",
        "test_set = concat_set.iloc[train_size:, :].copy()   # Get the original test rows"
      ],
      "metadata": {
        "id": "IB0XfR0by2P6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train set shape:\", train_set.shape)\n",
        "print(\"Test set shape:\", test_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIvbQJxZh7Rt",
        "outputId": "53594719-e299-4c2a-e15a-d1eac472c4bb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set shape: (140700, 125)\n",
            "Test set shape: (93800, 125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.to_csv('/content/Exploring-Mental-Health-Data/data/PP_train.csv', index=False)\n",
        "test_set.to_csv('/content/Exploring-Mental-Health-Data/data/PP_test.csv', index=False)"
      ],
      "metadata": {
        "id": "PyBBkAl4L4cZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for columns with object data type in train_set and test_set\n",
        "train_object_columns = train_set.select_dtypes(include=['object']).columns\n",
        "test_object_columns = test_set.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(\"Object columns in train_set:\", train_object_columns.tolist())\n",
        "print(\"Object columns in test_set:\", test_object_columns.tolist())\n",
        "\n",
        "# Check for columns with missing values in train_set and test_set\n",
        "train_missing = train_set.isna().sum()\n",
        "test_missing = test_set.isna().sum()\n",
        "\n",
        "print(\"\\nColumns with missing values in train_set:\")\n",
        "print(train_missing[train_missing > 0])\n",
        "\n",
        "print(\"\\nColumns with missing values in test_set:\")\n",
        "print(test_missing[test_missing > 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9bJQt9-mr6C",
        "outputId": "920ee37d-160a-46b0-9622-f05e3f1e4d2d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Object columns in train_set: []\n",
            "Object columns in test_set: []\n",
            "\n",
            "Columns with missing values in train_set:\n",
            "Series([], dtype: int64)\n",
            "\n",
            "Columns with missing values in test_set:\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_set.copy()\n",
        "y = target_variable"
      ],
      "metadata": {
        "id": "eUly5Sp4_gYa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_zJpYJuoDPF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "important_features = X.columns[feature_importances > 0.005]\n",
        "X_reduced = X[important_features]\n",
        "X_reduced.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg8iMQDb-1TE",
        "outputId": "85a2b4fb-0c04-4842-ccc1-e17c8d6df089"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'Academic Pressure', 'Work Pressure', 'Study Satisfaction',\n",
              "       'Job Satisfaction', 'Have you ever had suicidal thoughts ?',\n",
              "       'Work/Study Hours', 'Financial Stress', 'Academic/Work Pressure',\n",
              "       'Study/Job Satisfaction', 'Profession_freq', 'Profession_Chemist',\n",
              "       'Profession_Content Writer', 'Profession_Entrepreneur',\n",
              "       'Profession_Judge', 'Profession_Pharmacist', 'City_Ahmedabad', 'From',\n",
              "       'To', 'Dietary Habits_freq', 'Dietary Habits_Healthy',\n",
              "       'Dietary Habits_Unhealthy'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=5)\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n",
        "X_reduced_df = pd.DataFrame(X_reduced, columns=[f'PC{i+1}' for i in range(X_reduced.shape[1])])\n",
        "\n",
        "# Get explained variance ratio\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "# Display the cumulative variance\n",
        "cumulative_variance = explained_variance.cumsum()\n",
        "\n",
        "# Print explained variance and cumulative variance\n",
        "for i, var in enumerate(explained_variance):\n",
        "    print(f\"Principal Component {i+1}: {var:.4f} (Cumulative: {cumulative_variance[i]:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvXWn4KODndz",
        "outputId": "3ca73ce2-5ab8-4679-a36b-6a74063e563a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Principal Component 1: 0.8736 (Cumulative: 0.8736)\n",
            "Principal Component 2: 0.1180 (Cumulative: 0.9916)\n",
            "Principal Component 3: 0.0055 (Cumulative: 0.9971)\n",
            "Principal Component 4: 0.0025 (Cumulative: 0.9996)\n",
            "Principal Component 5: 0.0004 (Cumulative: 1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Lasso(alpha=0.01)\n",
        "model.fit(X, y)\n",
        "important_features = X.columns[model.coef_ != 0]\n",
        "X_reduced = X[important_features]\n",
        "X_reduced.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o8ts_k9DzgY",
        "outputId": "346baf77-577c-4084-d013-4e9e2375c2de"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'Academic Pressure', 'Have you ever had suicidal thoughts ?',\n",
              "       'Financial Stress', 'Academic/Work Pressure', 'Study/Job Satisfaction',\n",
              "       'City_freq', 'Degree_freq', 'Profession_freq', 'Profession_Teacher',\n",
              "       'From', 'To', 'Dietary Habits_freq', 'Dietary Habits_Unhealthy'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_set[['City_freq', 'Profession_freq',\n",
        "       'Profession_Teacher', 'Degree_freq', 'Dietary Habits_freq',\n",
        "       'Dietary Habits_Unhealthy', 'Age', 'Academic Pressure', 'Work Pressure', 'Study Satisfaction',\n",
        "       'Job Satisfaction', 'Have you ever had suicidal thoughts ?',\n",
        "       'Work/Study Hours', 'Financial Stress',\n",
        "       'Profession_Architect', 'Profession_Chemist',\n",
        "       'Profession_Content Writer', 'Profession_Entrepreneur',\n",
        "       'Profession_Judge', 'Profession_Pharmacist', 'Academic/Work Pressure',\n",
        "       'Study/Job Satisfaction', 'From', 'To',\n",
        "       'Dietary Habits_Healthy']] + X_reduced_df[['PC1', 'PC2', 'PC3', 'PC4', 'PC5']]"
      ],
      "metadata": {
        "id": "h6pmG59kFa7s"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_set.copy()\n",
        "y = target_variable\n",
        "\n",
        "# Initial split for training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
        "\n",
        "# Print the count of True and False in both train and validation sets\n",
        "print(\"Training set class distribution:\\n\", y_train.value_counts())\n",
        "print(\"Validation set class distribution:\\n\", y_val.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzZnoXOIGbOg",
        "outputId": "40681f5e-2e28-42c9-d4ff-647e46aea593"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set class distribution:\n",
            " Depression\n",
            "0    103620\n",
            "1     23010\n",
            "Name: count, dtype: int64\n",
            "Validation set class distribution:\n",
            " Depression\n",
            "0    11513\n",
            "1     2557\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import xgboost as xgb\n",
        "\n",
        "# List of model parameters\n",
        "model_parameters = [\n",
        "    {'colsample_bytree': 1.0, 'gamma': 0.0, 'learning_rate': 0.14053992185033634, 'max_depth': 2, 'n_estimators': 500, 'reg_alpha': 3.54988240208208, 'reg_lambda': 0.921308795529119, 'subsample': 0.5},\n",
        "    {'colsample_bytree': 0.9828642489404322, 'gamma': 3.8356539257184212, 'learning_rate': 0.24821760051945593, 'max_depth': 2, 'n_estimators': 496, 'reg_alpha': 1.9768655910871376, 'reg_lambda': 10.0, 'subsample': 0.6876446417339648},\n",
        "    {'colsample_bytree': 0.5482548720792537, 'gamma': 0.7585910862891333, 'learning_rate': 0.24362567776750851, 'max_depth': 2, 'n_estimators': 399, 'reg_alpha': 9.183318680337436, 'reg_lambda': 8.354951719581466, 'subsample': 0.9288717269361884},\n",
        "    {'colsample_bytree': 0.826258443653563, 'gamma': 0.2898189814539954, 'learning_rate': 0.1560857716723225, 'max_depth': 3, 'n_estimators': 252, 'reg_alpha': 9.909946019462808, 'reg_lambda': 8.794138788777472, 'subsample': 0.6086089653039243},\n",
        "    {'colsample_bytree': 0.5, 'gamma': 1.0613803072595367, 'learning_rate': 0.4309050398635545, 'max_depth': 2, 'n_estimators': 491, 'reg_alpha': 9.395079774043808, 'reg_lambda': 7.331815596626036, 'subsample': 0.5},\n",
        "    {'colsample_bytree': 1.0, 'gamma': 0.8055969826831805, 'learning_rate': 0.07850322110212825, 'max_depth': 2, 'n_estimators': 500, 'reg_alpha': 10.0, 'reg_lambda': 7.307261693189616, 'subsample': 0.5},\n",
        "    {'colsample_bytree': 0.5071052160640582, 'gamma': 6.532630659116698, 'learning_rate': 0.05917416968889502, 'max_depth': 41, 'n_estimators': 500, 'reg_alpha': 5.525276688982408, 'reg_lambda': 10.0, 'subsample': 0.8337729014389854},\n",
        "    {'colsample_bytree': 0.8682156936651646, 'gamma': 2.3661463968930123, 'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 500, 'reg_alpha': 6.878059550769972, 'reg_lambda': 10.0, 'subsample': 0.5},\n",
        "    {'colsample_bytree': 0.5038829468838858, 'gamma': 1.4575211520278655, 'learning_rate': 0.06985053383947529, 'max_depth': 6, 'n_estimators': 414, 'reg_alpha': 9.499001815481689, 'reg_lambda': 0.9976351956145648, 'subsample': 0.7122725319242551},\n",
        "    {'colsample_bytree': 0.9505559305966407, 'gamma': 0.0, 'learning_rate': 0.31034434048228005, 'max_depth': 2, 'n_estimators': 407, 'reg_alpha': 8.566301647743709, 'reg_lambda': 10.0, 'subsample': 0.6381124861311176},\n",
        "    {'colsample_bytree': 0.5271397711907289, 'gamma': 1.4882692983778134, 'learning_rate': 0.022613833933071845, 'max_depth': 70, 'n_estimators': 500, 'reg_alpha': 7.350122507234383, 'reg_lambda': 2.3467446363910205, 'subsample': 1.0},\n",
        "    {'colsample_bytree': 0.968269317216317, 'gamma': 0.7956592762847293, 'learning_rate': 0.22241747714939272, 'max_depth': 6, 'n_estimators': 268, 'reg_alpha': 9.61123872314133, 'reg_lambda': 1.0199763042557133, 'subsample': 0.9101921473710248},\n",
        "    {'colsample_bytree': 0.5010496053339198, 'gamma': 0.7546323022179792, 'learning_rate': 0.01860526126199002, 'max_depth': 12, 'n_estimators': 499, 'reg_alpha': 8.720527262017999, 'reg_lambda': 1.3463384912771639, 'subsample': 0.9265861439852696},\n",
        "    {'colsample_bytree': 0.5510220279765351, 'gamma': 7.984488731903994, 'learning_rate': 0.09183744558408916, 'max_depth': 60, 'n_estimators': 380, 'reg_alpha': 3.1539117758914, 'reg_lambda': 1.7690590466474512, 'subsample': 0.555548765738129},\n",
        "    {'colsample_bytree': 0.543245954963853, 'gamma': 2.7342452805864643, 'learning_rate': 0.04318592293247114, 'max_depth': 46, 'n_estimators': 362, 'reg_alpha': 4.0009466491413335, 'reg_lambda': 1.5685416376985208, 'subsample': 0.8836643772841459},\n",
        "]\n",
        "\n",
        "# Train and evaluate each model\n",
        "for i, params in enumerate(model_parameters, start=1):\n",
        "    print(f\"Training Model {i}...\")\n",
        "    model = xgb.XGBClassifier(**params, eval_metric='error')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on train and validation sets\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    y_test_pred = model.predict(test_set)\n",
        "\n",
        "    # Print classification reports\n",
        "    print(f\"Classification Report - Train (Model {i}):\")\n",
        "    print(classification_report(y_train, y_train_pred))\n",
        "\n",
        "    print(f\"Classification Report - Validation (Model {i}):\")\n",
        "    print(classification_report(y_val, y_val_pred))\n"
      ],
      "metadata": {
        "id": "5gbud1tQFWnK",
        "outputId": "7d7931bc-597e-42b2-ac89-3430c9e6740d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model 1...\n",
            "Classification Report - Train (Model 1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.84     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.89      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 1):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.84      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 2...\n",
            "Classification Report - Train (Model 2):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.83     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.89      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 2):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.85      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 3...\n",
            "Classification Report - Train (Model 3):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.83     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.90      0.89      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 3):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.85      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 4...\n",
            "Classification Report - Train (Model 4):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.84     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.89      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 4):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.84      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 5...\n",
            "Classification Report - Train (Model 5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.84     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.89      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 5):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.84      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 6...\n",
            "Classification Report - Train (Model 6):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.83     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.90      0.89      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 6):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.85      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 7...\n",
            "Classification Report - Train (Model 7):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.84     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.89      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 7):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.85      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 8...\n",
            "Classification Report - Train (Model 8):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.84     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.90      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 8):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.85      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 9...\n",
            "Classification Report - Train (Model 9):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97    103620\n",
            "           1       0.85      0.83      0.84     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.90      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 9):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.84      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 10...\n",
            "Classification Report - Train (Model 10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.84     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.89      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 10):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.85      0.81      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 11...\n",
            "Classification Report - Train (Model 11):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97    103620\n",
            "           1       0.87      0.84      0.85     23010\n",
            "\n",
            "    accuracy                           0.95    126630\n",
            "   macro avg       0.91      0.90      0.91    126630\n",
            "weighted avg       0.95      0.95      0.95    126630\n",
            "\n",
            "Classification Report - Validation (Model 11):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.85      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 12...\n",
            "Classification Report - Train (Model 12):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97    103620\n",
            "           1       0.86      0.84      0.85     23010\n",
            "\n",
            "    accuracy                           0.95    126630\n",
            "   macro avg       0.91      0.90      0.91    126630\n",
            "weighted avg       0.95      0.95      0.95    126630\n",
            "\n",
            "Classification Report - Validation (Model 12):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.84      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 13...\n",
            "Classification Report - Train (Model 13):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97    103620\n",
            "           1       0.87      0.84      0.85     23010\n",
            "\n",
            "    accuracy                           0.95    126630\n",
            "   macro avg       0.92      0.90      0.91    126630\n",
            "weighted avg       0.95      0.95      0.95    126630\n",
            "\n",
            "Classification Report - Validation (Model 13):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.84      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 14...\n",
            "Classification Report - Train (Model 14):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.84     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.90      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation (Model 14):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.84      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n",
            "Training Model 15...\n",
            "Classification Report - Train (Model 15):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97    103620\n",
            "           1       0.86      0.84      0.85     23010\n",
            "\n",
            "    accuracy                           0.95    126630\n",
            "   macro avg       0.91      0.90      0.91    126630\n",
            "weighted avg       0.95      0.95      0.95    126630\n",
            "\n",
            "Classification Report - Validation (Model 15):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.85      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter search space\n",
        "search_spaces = {\n",
        "    'learning_rate': Real(0.001, 0.5, 'uniform'),\n",
        "    'max_depth': Integer(2, 70),\n",
        "    'n_estimators': Integer(100, 500),\n",
        "    'subsample': Real(0.5, 1.0, 'uniform'),\n",
        "    'colsample_bytree': Real(0.5, 1.0, 'uniform'),\n",
        "    'gamma': Real(0, 10, 'uniform'),\n",
        "    'reg_alpha': Real(0, 10, 'uniform'),\n",
        "    'reg_lambda': Real(0, 10, 'uniform')\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier model with GPU support\n",
        "model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',  # Use for binary classification\n",
        "    tree_method='hist',  # Use GPU for training\n",
        "    verbosity=2\n",
        ")\n",
        "\n",
        "kf = KFold(n_splits=5)  # 5-fold cross-validation\n",
        "\n",
        "# Use 'accuracy' as the scoring metric\n",
        "optimizer = BayesSearchCV(\n",
        "    estimator=model,\n",
        "    search_spaces=search_spaces,\n",
        "    n_iter=256,\n",
        "    cv=kf,\n",
        "    scoring='accuracy',  # Change scoring metric to accuracy\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Fit the optimizer using X_train and y_train\n",
        "optimizer.fit(X_train, y_train)\n",
        "\n",
        "# Get cross-validation results\n",
        "cv_results = optimizer.cv_results_\n",
        "\n",
        "# Create a DataFrame to sort and filter the best models\n",
        "results_df = pd.DataFrame(cv_results)\n",
        "top_15_results = results_df.nlargest(15, 'mean_test_score')  # Get top 5 models by mean test score\n",
        "\n",
        "# Train each of the top 5 models on the full training data and save them\n",
        "top_15_models = []\n",
        "for i, row in top_15_results.iterrows():\n",
        "    params = row['params']\n",
        "    model = xgb.XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        tree_method='hist',\n",
        "        **params\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    top_15_models.append(model)\n",
        "\n",
        "# Print parameters and scores for the top 5 models\n",
        "for idx, model in enumerate(top_15_models):\n",
        "    print(f\"Model {idx + 1} parameters: {top_15_results.iloc[idx]['params']}\")\n",
        "    print(f\"Model {idx + 1} CV score: {top_15_results.iloc[idx]['mean_test_score']}\")\n",
        "\n",
        "print(\"Top 5 XGBoost models based on accuracy have been trained and saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afVvwGfYG4nh",
        "outputId": "23962b43-39b3-4c4d-e636-beec53c6117c"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "Model 1 parameters: OrderedDict([('colsample_bytree', 1.0), ('gamma', 0.0), ('learning_rate', 0.14053992185033634), ('max_depth', 2), ('n_estimators', 500), ('reg_alpha', 3.54988240208208), ('reg_lambda', 0.921308795529119), ('subsample', 0.5)])\n",
            "Model 1 CV score: 0.9397378188422965\n",
            "Model 2 parameters: OrderedDict([('colsample_bytree', 0.9828642489404322), ('gamma', 3.8356539257184212), ('learning_rate', 0.24821760051945593), ('max_depth', 2), ('n_estimators', 496), ('reg_alpha', 1.9768655910871376), ('reg_lambda', 10.0), ('subsample', 0.6876446417339648)])\n",
            "Model 2 CV score: 0.9396746426597172\n",
            "Model 3 parameters: OrderedDict([('colsample_bytree', 0.5482548720792537), ('gamma', 0.7585910862891333), ('learning_rate', 0.24362567776750851), ('max_depth', 2), ('n_estimators', 399), ('reg_alpha', 9.183318680337436), ('reg_lambda', 8.354951719581466), ('subsample', 0.9288717269361884)])\n",
            "Model 3 CV score: 0.9394535260206902\n",
            "Model 4 parameters: OrderedDict([('colsample_bytree', 0.826258443653563), ('gamma', 0.2898189814539954), ('learning_rate', 0.1560857716723225), ('max_depth', 3), ('n_estimators', 252), ('reg_alpha', 9.909946019462808), ('reg_lambda', 8.794138788777472), ('subsample', 0.6086089653039243)])\n",
            "Model 4 CV score: 0.9394456289978678\n",
            "Model 5 parameters: OrderedDict([('colsample_bytree', 0.5), ('gamma', 1.0613803072595367), ('learning_rate', 0.4309050398635545), ('max_depth', 2), ('n_estimators', 491), ('reg_alpha', 9.395079774043808), ('reg_lambda', 7.331815596626036), ('subsample', 0.5)])\n",
            "Model 5 CV score: 0.9394377319750454\n",
            "Model 6 parameters: OrderedDict([('colsample_bytree', 1.0), ('gamma', 0.8055969826831805), ('learning_rate', 0.07850322110212825), ('max_depth', 2), ('n_estimators', 500), ('reg_alpha', 10.0), ('reg_lambda', 7.307261693189616), ('subsample', 0.5)])\n",
            "Model 6 CV score: 0.9393745557924662\n",
            "Model 7 parameters: OrderedDict([('colsample_bytree', 0.5071052160640582), ('gamma', 6.532630659116698), ('learning_rate', 0.05917416968889502), ('max_depth', 41), ('n_estimators', 500), ('reg_alpha', 5.525276688982408), ('reg_lambda', 10.0), ('subsample', 0.8337729014389854)])\n",
            "Model 7 CV score: 0.9393666587696439\n",
            "Model 8 parameters: OrderedDict([('colsample_bytree', 0.8682156936651646), ('gamma', 2.3661463968930123), ('learning_rate', 0.5), ('max_depth', 2), ('n_estimators', 500), ('reg_alpha', 6.878059550769972), ('reg_lambda', 10.0), ('subsample', 0.5)])\n",
            "Model 8 CV score: 0.9393429677011766\n",
            "Model 9 parameters: OrderedDict([('colsample_bytree', 0.5038829468838858), ('gamma', 1.4575211520278655), ('learning_rate', 0.06985053383947529), ('max_depth', 6), ('n_estimators', 414), ('reg_alpha', 9.499001815481689), ('reg_lambda', 0.9976351956145648), ('subsample', 0.7122725319242551)])\n",
            "Model 9 CV score: 0.9393429677011766\n",
            "Model 10 parameters: OrderedDict([('colsample_bytree', 0.9505559305966407), ('gamma', 0.0), ('learning_rate', 0.31034434048228005), ('max_depth', 2), ('n_estimators', 407), ('reg_alpha', 8.566301647743709), ('reg_lambda', 10.0), ('subsample', 0.6381124861311176)])\n",
            "Model 10 CV score: 0.9391850272447287\n",
            "Model 11 parameters: OrderedDict([('colsample_bytree', 0.5271397711907289), ('gamma', 1.4882692983778134), ('learning_rate', 0.022613833933071845), ('max_depth', 70), ('n_estimators', 500), ('reg_alpha', 7.350122507234383), ('reg_lambda', 2.3467446363910205), ('subsample', 1.0)])\n",
            "Model 11 CV score: 0.9391139540393272\n",
            "Model 12 parameters: OrderedDict([('colsample_bytree', 0.968269317216317), ('gamma', 0.7956592762847293), ('learning_rate', 0.22241747714939272), ('max_depth', 6), ('n_estimators', 268), ('reg_alpha', 9.61123872314133), ('reg_lambda', 1.0199763042557133), ('subsample', 0.9101921473710248)])\n",
            "Model 12 CV score: 0.9390981599936824\n",
            "Model 13 parameters: OrderedDict([('colsample_bytree', 0.5010496053339198), ('gamma', 0.7546323022179792), ('learning_rate', 0.01860526126199002), ('max_depth', 12), ('n_estimators', 499), ('reg_alpha', 8.720527262017999), ('reg_lambda', 1.3463384912771639), ('subsample', 0.9265861439852696)])\n",
            "Model 13 CV score: 0.9390823659480375\n",
            "Model 14 parameters: OrderedDict([('colsample_bytree', 0.5510220279765351), ('gamma', 7.984488731903994), ('learning_rate', 0.09183744558408916), ('max_depth', 60), ('n_estimators', 380), ('reg_alpha', 3.1539117758914), ('reg_lambda', 1.7690590466474512), ('subsample', 0.555548765738129)])\n",
            "Model 14 CV score: 0.9390586748795704\n",
            "Model 15 parameters: OrderedDict([('colsample_bytree', 0.543245954963853), ('gamma', 2.7342452805864643), ('learning_rate', 0.04318592293247114), ('max_depth', 46), ('n_estimators', 362), ('reg_alpha', 4.0009466491413335), ('reg_lambda', 1.5685416376985208), ('subsample', 0.8836643772841459)])\n",
            "Model 15 CV score: 0.9390507778567481\n",
            "Top 5 XGBoost models based on accuracy have been trained and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zw97U_9ZFVuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import xgboost as xgb\n",
        "\n",
        "params1 = {\n",
        "    'colsample_bytree': 1.0,\n",
        "    'gamma': 0.0,\n",
        "    'learning_rate': 0.14053992185033634,\n",
        "    'max_depth': 2,\n",
        "    'n_estimators': 500,\n",
        "    'reg_alpha': 3.54988240208208,\n",
        "    'reg_lambda': 0.921308795529119,\n",
        "    'subsample': 0.5\n",
        "}\n",
        "# Define the model with the provided parameters\n",
        "xgb_model1 = xgb.XGBClassifier(**params1, eval_metric='error')\n",
        "\n",
        "# Train the model\n",
        "xgb_model1.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on train set\n",
        "y_pred_prob_XGB1_train = xgb_model1.predict(X_train)\n",
        "print(\"Classification Report - Train:\")\n",
        "print(classification_report(y_train, y_pred_prob_XGB1_train))\n",
        "\n",
        "# Predictions on validation set\n",
        "y_pred_prob_XGB1_val = xgb_model1.predict(X_val)\n",
        "print(\"Classification Report - Validation:\")\n",
        "print(classification_report(y_val, y_pred_prob_XGB1_val))\n",
        "\n",
        "y_pred_prob_XGB1_test = xgb_model1.predict(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PlDkzo6JPrs",
        "outputId": "998413dc-0702-45ae-adac-d8e0b89934cf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report - Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96    103620\n",
            "           1       0.85      0.82      0.84     23010\n",
            "\n",
            "    accuracy                           0.94    126630\n",
            "   macro avg       0.91      0.89      0.90    126630\n",
            "weighted avg       0.94      0.94      0.94    126630\n",
            "\n",
            "Classification Report - Validation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96     11513\n",
            "           1       0.84      0.82      0.83      2557\n",
            "\n",
            "    accuracy                           0.94     14070\n",
            "   macro avg       0.90      0.89      0.90     14070\n",
            "weighted avg       0.94      0.94      0.94     14070\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Prepare the output DataFrame\n",
        "output = pd.DataFrame({'id': test_id.values, 'loan_status': y_pred_prob_XGB1_test})\n",
        "\n",
        "# Remove any duplicate rows by 'PassengerId'\n",
        "output.drop_duplicates(subset='id', keep='first', inplace=True)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "output.to_csv('predictions.csv', index=False)\n",
        "files.download('predictions.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VL_UOI0LpxxV",
        "outputId": "ffe0293d-23b3-4f87-fecb-ecf245c208cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8f4a5d2f-6819-466f-a6dd-fb2cc419ef03\", \"predictions.csv\", 844215)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}