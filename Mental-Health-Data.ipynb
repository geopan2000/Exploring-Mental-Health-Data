{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZRkcPGV0nYkUlrje9XJRL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geopan2000/Exploring-Mental-Health-Data/blob/main/Mental-Health-Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-qSSzXu6sNOP",
        "outputId": "dd4dcaa1-4272-4fe6-c5a5-8e37fbed6765",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Exploring-Mental-Health-Data'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 36 (delta 9), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36/36), 5.48 MiB | 3.17 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n",
            "/content/Exploring-Mental-Health-Data/Exploring-Mental-Health-Data/Exploring-Mental-Health-Data\n"
          ]
        }
      ],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/geopan2000/Exploring-Mental-Health-Data.git\n",
        "\n",
        "# Change directory to the cloned repository\n",
        "%cd Exploring-Mental-Health-Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "!pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "!pip install scikit-optimize\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "import xgboost as xgb\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "xy-6SSxfCTjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97937ff3-98bb-4bb8-c28a-3e7ea7bf1c9e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = pd.read_csv('/content/Exploring-Mental-Health-Data/data/train.csv')\n",
        "test_set = pd.read_csv('/content/Exploring-Mental-Health-Data/data/test.csv')"
      ],
      "metadata": {
        "id": "yh9AABJ5CX0f"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.head()"
      ],
      "metadata": {
        "id": "UQzDBpoXCip3",
        "outputId": "f1dbc852-6994-4421-f89f-2b7f6fcb6953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id      Name  Gender   Age           City Working Professional or Student  \\\n",
              "0   0  Aaradhya  Female  49.0       Ludhiana            Working Professional   \n",
              "1   1     Vivan    Male  26.0       Varanasi            Working Professional   \n",
              "2   2    Yuvraj    Male  33.0  Visakhapatnam                         Student   \n",
              "3   3    Yuvraj    Male  22.0         Mumbai            Working Professional   \n",
              "4   4      Rhea  Female  30.0         Kanpur            Working Professional   \n",
              "\n",
              "         Profession  Academic Pressure  Work Pressure  CGPA  \\\n",
              "0              Chef                NaN            5.0   NaN   \n",
              "1           Teacher                NaN            4.0   NaN   \n",
              "2               NaN                5.0            NaN  8.97   \n",
              "3           Teacher                NaN            5.0   NaN   \n",
              "4  Business Analyst                NaN            1.0   NaN   \n",
              "\n",
              "   Study Satisfaction  Job Satisfaction     Sleep Duration Dietary Habits  \\\n",
              "0                 NaN               2.0  More than 8 hours        Healthy   \n",
              "1                 NaN               3.0  Less than 5 hours      Unhealthy   \n",
              "2                 2.0               NaN          5-6 hours        Healthy   \n",
              "3                 NaN               1.0  Less than 5 hours       Moderate   \n",
              "4                 NaN               1.0          5-6 hours      Unhealthy   \n",
              "\n",
              "    Degree Have you ever had suicidal thoughts ?  Work/Study Hours  \\\n",
              "0      BHM                                    No               1.0   \n",
              "1      LLB                                   Yes               7.0   \n",
              "2  B.Pharm                                   Yes               3.0   \n",
              "3      BBA                                   Yes              10.0   \n",
              "4      BBA                                   Yes               9.0   \n",
              "\n",
              "   Financial Stress Family History of Mental Illness  Depression  \n",
              "0               2.0                               No           0  \n",
              "1               3.0                               No           1  \n",
              "2               1.0                               No           1  \n",
              "3               1.0                              Yes           1  \n",
              "4               4.0                              Yes           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-281013ae-b5ca-4044-9800-679920e83a86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Name</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>City</th>\n",
              "      <th>Working Professional or Student</th>\n",
              "      <th>Profession</th>\n",
              "      <th>Academic Pressure</th>\n",
              "      <th>Work Pressure</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Study Satisfaction</th>\n",
              "      <th>Job Satisfaction</th>\n",
              "      <th>Sleep Duration</th>\n",
              "      <th>Dietary Habits</th>\n",
              "      <th>Degree</th>\n",
              "      <th>Have you ever had suicidal thoughts ?</th>\n",
              "      <th>Work/Study Hours</th>\n",
              "      <th>Financial Stress</th>\n",
              "      <th>Family History of Mental Illness</th>\n",
              "      <th>Depression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Aaradhya</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Ludhiana</td>\n",
              "      <td>Working Professional</td>\n",
              "      <td>Chef</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>More than 8 hours</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>BHM</td>\n",
              "      <td>No</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Vivan</td>\n",
              "      <td>Male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>Varanasi</td>\n",
              "      <td>Working Professional</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Less than 5 hours</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>LLB</td>\n",
              "      <td>Yes</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Yuvraj</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.0</td>\n",
              "      <td>Visakhapatnam</td>\n",
              "      <td>Student</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.97</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5-6 hours</td>\n",
              "      <td>Healthy</td>\n",
              "      <td>B.Pharm</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Yuvraj</td>\n",
              "      <td>Male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>Working Professional</td>\n",
              "      <td>Teacher</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Less than 5 hours</td>\n",
              "      <td>Moderate</td>\n",
              "      <td>BBA</td>\n",
              "      <td>Yes</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Rhea</td>\n",
              "      <td>Female</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Kanpur</td>\n",
              "      <td>Working Professional</td>\n",
              "      <td>Business Analyst</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5-6 hours</td>\n",
              "      <td>Unhealthy</td>\n",
              "      <td>BBA</td>\n",
              "      <td>Yes</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-281013ae-b5ca-4044-9800-679920e83a86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-281013ae-b5ca-4044-9800-679920e83a86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-281013ae-b5ca-4044-9800-679920e83a86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cf2e1f3f-1c7e-4376-b79e-e19ab7c5f5fe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf2e1f3f-1c7e-4376-b79e-e19ab7c5f5fe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cf2e1f3f-1c7e-4376-b79e-e19ab7c5f5fe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_set"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Inspection"
      ],
      "metadata": {
        "id": "g7oFrxdGWvhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train_print = train_set.copy()\n",
        "#train_print = train_print.drop(columns=['Depression'])\n",
        "\n",
        "#for column in train_print.columns:\n",
        "    #train_nan_ratio = train_print[column].isna().sum() / len(train_print)  # Proportion of NaN in train set\n",
        "    #test_nan_ratio = test_set[column].isna().sum() / len(test_set)  # Proportion of NaN in test set\n",
        "    #print(f\"{column}  Train Set: {train_nan_ratio:.2%} Test Set: {test_nan_ratio:.2%}\")"
      ],
      "metadata": {
        "id": "KhM0uFVhZF9l"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the value counts for train and test sets\n",
        "#train_counts = train_set['Profession'].value_counts()\n",
        "#test_counts = test_set['Profession'].value_counts()\n",
        "\n",
        "# Get a combined set of unique values from both train and test sets\n",
        "#all_professions = set(train_counts.index).union(set(test_counts.index))\n",
        "\n",
        "# Print the counts for each profession\n",
        "#for profession in all_professions:\n",
        " #   train_count = train_counts.get(profession, 0)  # Get count from train, default to 0\n",
        "  #  test_count = test_counts.get(profession, 0)   # Get count from test, default to 0\n",
        "   # print(f\"{profession}: Train_set={train_count} Test_set={test_count}\")"
      ],
      "metadata": {
        "id": "uNd2rFkFcDAa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering:\n"
      ],
      "metadata": {
        "id": "qm9h56dJLbEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_id = train_set['id']\n",
        "print(train_set['id'].shape)\n",
        "\n",
        "target_variable = train_set['Depression']\n",
        "train_set.drop(columns=['Name','Depression'], inplace=True)\n",
        "test_id = test_set['id']\n",
        "print(test_set['id'].shape)\n",
        "test_set.drop(columns=['Name'], inplace=True)\n",
        "\n",
        "train_set['Gender'] = train_set['Gender'].map({'Male' : 1, 'Female' : 0}) # Always trasnforming 2 option object types into binary\n",
        "test_set['Gender'] = test_set['Gender'].map({'Male' : 1, 'Female' : 0})\n",
        "\n",
        "train_set['Age'] = train_set['Age'] / 100 # Normalized by the Max value\n",
        "train_set['Age'] = train_set['Age'].fillna(train_set['Age'].mean())\n",
        "test_set['Age'] = test_set['Age'] / 100\n",
        "test_set['Age'] = test_set['Age'].fillna(test_set['Age'].mean())\n",
        "\n",
        "train_set['Working Professional or Student'] = train_set['Working Professional or Student'].map({'Working Professional' : 1, 'Student' : 0}) # Always trasnforming 2 option object types into binary\n",
        "test_set['Working Professional or Student'] = test_set['Working Professional or Student'].map({'Working Professional' : 1, 'Student' : 0})\n",
        "\n",
        "train_set['CGPA'] = train_set['CGPA'] /10\n",
        "train_set['CGPA'] = train_set['CGPA'].fillna(0)\n",
        "test_set['CGPA'] = test_set['CGPA'] /10\n",
        "test_set['CGPA'] = test_set['CGPA'].fillna(0)\n",
        "\n",
        "train_set['Have you ever had suicidal thoughts ?'] = train_set['Have you ever had suicidal thoughts ?'].map({'Yes' : 1, 'No' : 0}) # Always trasnforming 2 option object types into binary\n",
        "test_set['Have you ever had suicidal thoughts ?'] = test_set['Have you ever had suicidal thoughts ?'].map({'Yes' : 1, 'No' : 0})\n",
        "\n",
        "train_set['Work/Study Hours'] = train_set['Work/Study Hours'] / 24 # Normalized by the Max value\n",
        "test_set['Work/Study Hours'] = test_set['Work/Study Hours'] / 24\n",
        "\n",
        "train_set['Financial Stress'] = train_set['Financial Stress'] / 5 # Normalized by the Max value\n",
        "train_set['Financial Stress'] = train_set['Financial Stress'].fillna(0)\n",
        "test_set['Financial Stress'] = test_set['Financial Stress'] / 5\n",
        "test_set['Financial Stress'] = test_set['Financial Stress'].fillna(0)\n",
        "\n",
        "train_set['Family History of Mental Illness'] = train_set['Family History of Mental Illness'].map({'Yes' : 1, 'No' : 0}) # Always trasnforming 2 option object types into binary\n",
        "test_set['Family History of Mental Illness'] = test_set['Family History of Mental Illness'].map({'Yes' : 1, 'No' : 0})"
      ],
      "metadata": {
        "id": "9DqcZW0JLXRz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new feature 'Academic/Work Pressure'\n",
        "train_set['Academic/Work Pressure'] = train_set.apply(\n",
        "    lambda row: row['Academic Pressure'] if pd.notna(row['Academic Pressure']) and pd.isna(row['Work Pressure']) else\n",
        "                row['Work Pressure'] if pd.isna(row['Academic Pressure']) and pd.notna(row['Work Pressure']) else\n",
        "                (row['Academic Pressure'] + row['Work Pressure']) / 2 if pd.notna(row['Academic Pressure']) and pd.notna(row['Work Pressure']) else\n",
        "                None,  # Placeholder for rows where both are NaN\n",
        "    axis=1)\n",
        "\n",
        "# Fill any remaining NaN in 'Academic/Work Pressure' with its mean\n",
        "train_set['Academic/Work Pressure'] = train_set['Academic/Work Pressure'].fillna(train_set['Academic/Work Pressure'].mean())\n",
        "\n",
        "train_set['Academic Pressure'] = train_set['Academic Pressure'] / 5\n",
        "train_set['Academic Pressure'] = train_set['Academic Pressure'].fillna(0)\n",
        "\n",
        "train_set['Work Pressure'] = train_set['Work Pressure'] / 5\n",
        "train_set['Work Pressure'] = train_set['Work Pressure'].fillna(0)"
      ],
      "metadata": {
        "id": "nsrLzYkZNrf8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the new feature Study/Job Satisfaction\n",
        "train_set['Study/Job Satisfaction'] = train_set.apply(\n",
        "    lambda row: row['Study Satisfaction'] if pd.notna(row['Study Satisfaction']) and pd.isna(row['Job Satisfaction']) else\n",
        "                row['Job Satisfaction'] if pd.isna(row['Study Satisfaction']) and pd.notna(row['Job Satisfaction']) else\n",
        "                (row['Study Satisfaction'] + row['Job Satisfaction']) / 2 if pd.notna(row['Study Satisfaction']) and pd.notna(row['Job Satisfaction']) else\n",
        "                None,  # Placeholder for rows where both are NaN\n",
        "    axis=1)\n",
        "\n",
        "# Fill any remaining NaN in Study/Job Satisfaction with its mean\n",
        "train_set['Study/Job Satisfaction'] = train_set['Study/Job Satisfaction'].fillna(train_set['Study/Job Satisfaction'].mean())\n",
        "\n",
        "train_set['Study Satisfaction'] = train_set['Study Satisfaction'] / 5\n",
        "train_set['Study Satisfaction'] = train_set['Study Satisfaction'].fillna(0)\n",
        "\n",
        "train_set['Job Satisfaction'] = train_set['Job Satisfaction'] / 5\n",
        "train_set['Job Satisfaction'] = train_set['Job Satisfaction'].fillna(0)"
      ],
      "metadata": {
        "id": "RLBK-FG1Ny4C"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and test value counts\n",
        "train_counts = train_set['City'].value_counts()\n",
        "test_counts = test_set['City'].value_counts()\n",
        "\n",
        "# Create a combined count of professions\n",
        "combined_counts = train_counts.add(test_counts, fill_value=0)\n",
        "\n",
        "# Identify professions appearing less than 5 times in either set\n",
        "low_frequency_values = combined_counts[combined_counts < 10].index.tolist()\n",
        "\n",
        "# Map low-frequency values to 'None' in both train and test sets\n",
        "train_set['City'] = train_set['City'].apply(lambda x: 'Other' if x in low_frequency_values else x)\n",
        "test_set['City'] = test_set['City'].apply(lambda x: 'Other' if x in low_frequency_values else x)"
      ],
      "metadata": {
        "id": "WBJlJvkDQNkT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and test value counts\n",
        "train_counts = train_set['Profession'].value_counts()\n",
        "test_counts = test_set['Profession'].value_counts()\n",
        "\n",
        "# Create a combined count of professions\n",
        "combined_counts = train_counts.add(test_counts, fill_value=0)\n",
        "\n",
        "# Identify professions appearing less than 5 times in either set\n",
        "low_frequency_values = combined_counts[combined_counts < 10].index.tolist()\n",
        "\n",
        "# Map low-frequency values to 'None' in both train and test sets\n",
        "train_set['Profession'] = train_set['Profession'].apply(lambda x: 'Other' if x in low_frequency_values else x)\n",
        "test_set['Profession'] = test_set['Profession'].apply(lambda x: 'Other' if x in low_frequency_values else x)"
      ],
      "metadata": {
        "id": "jtPh01G6P8IL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine train and test value counts\n",
        "train_counts = train_set['Degree'].value_counts()\n",
        "test_counts = test_set['Degree'].value_counts()\n",
        "\n",
        "# Create a combined count of professions\n",
        "combined_counts = train_counts.add(test_counts, fill_value=0)\n",
        "\n",
        "# Identify professions appearing less than 5 times in either set\n",
        "low_frequency_values = combined_counts[combined_counts < 10].index.tolist()\n",
        "\n",
        "# Map low-frequency values to 'None' in both train and test sets\n",
        "train_set['Degree'] = train_set['Degree'].apply(lambda x: 'Other' if x in low_frequency_values else x)\n",
        "test_set['Degree'] = test_set['Degree'].apply(lambda x: 'Other' if x in low_frequency_values else x)"
      ],
      "metadata": {
        "id": "SXwCvPvIQdpq"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set['City'] = train_set['City'].fillna('X')\n",
        "freq = train_set['City'].value_counts()\n",
        "train_set['City_freq'] = train_set['City'].map(freq) # Frequency encoding different cities\n",
        "\n",
        "test_set['City'] = test_set['City'].fillna('X')\n",
        "test_set['City_freq'] = test_set['City'].map(freq) # Frequency encoding different cities\n",
        "\n",
        "\n",
        "train_set['Degree'] = train_set['Degree'].fillna('X')\n",
        "freq = train_set['Degree'].value_counts()\n",
        "train_set['Degree_freq'] = train_set['Degree'].map(freq) # Frequency encoding\n",
        "\n",
        "test_set['Degree'] = test_set['Degree'].fillna('X')\n",
        "test_set['Degree_freq'] = test_set['Degree'].map(freq) # Frequency encoding\n",
        "\n",
        "\n",
        "train_set['Profession'] = train_set['Profession'].fillna('X')\n",
        "freq = train_set['Profession'].value_counts()\n",
        "train_set['Profession_freq'] = train_set['Profession'].map(freq) # Frequency encoding\n",
        "\n",
        "test_set['Profession'] = test_set['Profession'].fillna('X')\n",
        "test_set['Profession_freq'] = test_set['Profession'].map(freq) # Frequency encoding"
      ],
      "metadata": {
        "id": "bm168rqvSxtd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the original number of rows for splitting later\n",
        "train_size = len(train_set)\n",
        "\n",
        "# Concatenate train and test sets\n",
        "concat_set = pd.concat([train_set, test_set], axis=0)\n",
        "\n",
        "# Apply one-hot encoding to the concatenated set\n",
        "concat_set = pd.get_dummies(concat_set, columns=['Degree', 'Profession', 'City'])\n",
        "\n",
        "# Split the concatenated set back into train and test sets\n",
        "train_set = concat_set.iloc[:train_size, :].copy()  # Get the original train rows\n",
        "test_set = concat_set.iloc[train_size:, :].copy()   # Get the original test rows\n",
        "\n",
        "print(\"Train set shape:\", train_set.shape)\n",
        "print(\"Test set shape:\", test_set.shape)"
      ],
      "metadata": {
        "id": "mdoyvMXlhcZn"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YM_HFAdg5Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Define a function to encode Sleep Duration\n",
        "def encode_sleep_duration(value):\n",
        "    # Check for NaN or None\n",
        "    if pd.isna(value):\n",
        "        return -1  # Placeholder for missing or invalid values\n",
        "\n",
        "    # Ensure the value is a string\n",
        "    value = str(value).strip()\n",
        "\n",
        "    # Encoding logic\n",
        "    if 'Less than 5 hours' in value or value in ['3-4 hours', '4-5 hours', '2-3 hours']:\n",
        "        return 1  # < 5 hours\n",
        "    elif '5-6 hours' in value:\n",
        "        return 2  # 5-6 hours\n",
        "    elif '6-7 hours' in value or '6-8 hours' in value:\n",
        "        return 3  # 6-7 hours\n",
        "    elif '7-8 hours' in value:\n",
        "        return 4  # 7-8 hours\n",
        "    elif 'More than 8 hours' in value or '8-9 hours' in value or '9-11 hours' in value:\n",
        "        return 5  # > 8 hours\n",
        "    else:\n",
        "        return -1  # Placeholder for other invalid or unclear values\n",
        "\n",
        "sleep_mapping = {\n",
        "    'More than 8 hours': '>8',\n",
        "    'Less than 5 hours': '<5',\n",
        "    'Moderate': '5-6 hours',\n",
        "    '9-6 hours': '6-9 hours',\n",
        "\n",
        "    '10-6 hours': '6-10 hours',\n",
        "    'than 5 hours': '4-6 hours',\n",
        "    'Unhealthy': '4-6 hours',\n",
        "    '9-5 hours': '5-9 hours',\n",
        "    '9-5': '5-9 hours',\n",
        "    '8-89 hours': '8-9 hours',\n",
        "\n",
        "    # Ambiguous or irrelevant entries\n",
        "    'Sleep_Duration': None, '40-45 hours': None, '55-66 hours': None, 'Indore': None,\n",
        "    '45': None, '35-36 hours': None, 'No': None, 'Indore': None, '49 hours': None,\n",
        "    'Work_Study_Hours': None, '45-48 hours': None, 'Pune': None, 'Soham': None,\n",
        "    '0': None, 'Meerut': None, '60-65 hours': None, 'Vivan': None,\n",
        "    'Have_you_ever_had_suicidal_thoughts': None, '20-21 hours': None, '50-75 hours': None\n",
        "}\n",
        "\n",
        "# Define range extraction function\n",
        "def extract_range(value):\n",
        "    try:\n",
        "        if '-' in value:\n",
        "            parts = value.split('-')\n",
        "            return int(parts[0]), int(parts[1].split()[0])\n",
        "        elif '<' in value:\n",
        "            return 3, 5\n",
        "        elif '>' in value:\n",
        "            lower_bound = int(value.split('>')[1].split()[0])\n",
        "            return lower_bound, 10\n",
        "        elif value.isdigit():\n",
        "            num = int(value)\n",
        "            return num, num\n",
        "        else:\n",
        "            return None, None\n",
        "    except:\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "Kv_Tsp9Gxkl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set['Sleep Duration'] = train_set['Sleep Duration'].map(sleep_mapping)\n",
        "train_set['Sleep_Duration_Encoded'] = train_set['Sleep Duration'].apply(encode_sleep_duration)\n",
        "\n",
        "# Apply the function to create 'From' and 'To' columns\n",
        "train_set[['From', 'To']] = train_set['Sleep Duration'].apply(lambda x: pd.Series(extract_range(x)))\n",
        "\n",
        "# Handle missing values\n",
        "train_set['From'] = train_set['From'].fillna(train_set['From'].mean())\n",
        "train_set['To'] = train_set['To'].fillna(train_set['To'].mean())\n",
        "\n",
        "# Drop the original column if not needed\n",
        "train_set.drop(columns=['Sleep Duration'], inplace=True)"
      ],
      "metadata": {
        "id": "l9dczY77kt9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define mapping for valid dietary habits\n",
        "dietary_mapping = {\n",
        "    'Moderate': 'Moderate',\n",
        "    'Unhealthy': 'Unhealthy',\n",
        "    'Healthy': 'Healthy',\n",
        "    'More Healthy': 'Healthy',\n",
        "    'Less Healthy': 'Unhealthy',\n",
        "    'Less than Healthy': 'Unhealthy',\n",
        "    'No Healthy': 'Unhealthy',\n",
        "    '3': 'Moderate',\n",
        "    '1.0': 'Unhealthy',\n",
        "    '2': 'Moderate',\n",
        "    '5 Healthy': 'Healthy',\n",
        "    '5 Unhealthy': 'Unhealthy',\n",
        "\n",
        "    # Ambiguous or irrelevant entries\n",
        "    'Yes': None, 'No': None, 'No Healthy': None, 'Class 12': None, 'Indoor': None,\n",
        "    'Male': None, 'Vegas': None, 'M.Tech': None, 'Electrician': None,\n",
        "    'Hormonal': None, 'Mihir': None, 'Gender': None, 'BSc': None,\n",
        "    'Pratham': None, 'Prachi': None, 'Resistant': None, 'Mealy': None,\n",
        "\n",
        "    'nan': None, 'Academic': None, 'Educational': None, 'Soham': None,\n",
        "    'Naina': None, 'Kolkata': None, 'Raghav': None, 'Vivaan': None,  'MCA': None,\n",
        "}\n",
        "\n",
        "# Apply the mapping to the Dietary Habits column\n",
        "train_set['Dietary Habits'] = train_set['Dietary Habits'].map(dietary_mapping)\n",
        "train_set['Dietary Habits'] = train_set['Dietary Habits'].fillna('X')\n",
        "train_set['Dietary Habits_freq'] = train_set['Dietary Habits'].map(train_set['Dietary Habits'].value_counts()) # frequency encoding\n",
        "train_set = pd.get_dummies(train_set, columns=['Dietary Habits']) # dummy variables"
      ],
      "metadata": {
        "id": "IB0XfR0by2P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_set.copy()\n",
        "y = X['Depression']\n",
        "X = X.drop(columns=['Depression'])"
      ],
      "metadata": {
        "id": "eUly5Sp4_gYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering: Test Data"
      ],
      "metadata": {
        "id": "ppe-Wr2DUtpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = test_set['id']\n",
        "test_set.drop(columns=['Name', 'id'], inplace=True)\n",
        "\n",
        "test_set['Gender'] = test_set['Gender'].map({'Male' : 1, 'Female' : 0}) #Always trasnforming 2 option object types into binary\n",
        "\n",
        "test_set['Age'] = test_set['Age'] / 100 #Normalized by the Max value\n",
        "test_set['Age'] = test_set['Age'].fillna(test_set['Age'].mean())\n",
        "\n",
        "test_set['City'] = test_set['City'].fillna('X')\n",
        "test_set['City_freq'] = test_set['City'].map(test_set['City'].value_counts()) # frequency encoding\n",
        "test_set = pd.get_dummies(test_set, columns=['City'])\n",
        "\n",
        "test_set['Working Professional or Student'] = test_set['Working Professional or Student'].map({'Working Professional' : 1, 'Student': 0}) #Always trasnforming 2 option object types into binary\n",
        "\n",
        "test_set['Profession'] = test_set['Profession'].fillna('X')\n",
        "test_set['Profession_freq'] = test_set['Profession'].map(test_set['Profession'].value_counts()) # frequency encoding\n",
        "test_set = pd.get_dummies(test_set, columns=['Profession'])\n",
        "\n",
        "# Create the new feature 'Academic/Work Pressure'\n",
        "test_set['Academic/Work Pressure'] = test_set.apply(\n",
        "    lambda row: row['Academic Pressure'] if pd.notna(row['Academic Pressure']) and pd.isna(row['Work Pressure']) else\n",
        "                row['Work Pressure'] if pd.isna(row['Academic Pressure']) and pd.notna(row['Work Pressure']) else\n",
        "                (row['Academic Pressure'] + row['Work Pressure']) / 2 if pd.notna(row['Academic Pressure']) and pd.notna(row['Work Pressure']) else\n",
        "                None,  # Placeholder for rows where both are NaN\n",
        "    axis=1)\n",
        "\n",
        "# Fill any remaining NaN in 'Academic/Work Pressure' with its mean\n",
        "test_set['Academic/Work Pressure'] = test_set['Academic/Work Pressure'].fillna(test_set['Academic/Work Pressure'].mean())\n",
        "\n",
        "test_set['Academic Pressure'] = test_set['Academic Pressure'] / 5\n",
        "test_set['Academic Pressure'] = test_set['Academic Pressure'].fillna(0)\n",
        "\n",
        "test_set['Work Pressure'] = test_set['Work Pressure'] / 5\n",
        "test_set['Work Pressure'] = test_set['Work Pressure'].fillna(0)\n",
        "\n",
        "test_set['CGPA'] = test_set['CGPA'] /10\n",
        "test_set['CGPA'] = test_set['CGPA'].fillna(0)\n",
        "\n",
        "# Create the new feature 'Study/Job Satisfaction'\n",
        "test_set['Study/Job Satisfaction'] = test_set.apply(\n",
        "    lambda row: row['Study Satisfaction'] if pd.notna(row['Study Satisfaction']) and pd.isna(row['Job Satisfaction']) else\n",
        "                row['Job Satisfaction'] if pd.isna(row['Study Satisfaction']) and pd.notna(row['Job Satisfaction']) else\n",
        "                (row['Study Satisfaction'] + row['Job Satisfaction']) / 2 if pd.notna(row['Study Satisfaction']) and pd.notna(row['Job Satisfaction']) else\n",
        "                None,  # Placeholder for rows where both are NaN\n",
        "    axis=1)\n",
        "\n",
        "# Fill any remaining NaN in 'Study/Job Satisfaction' with its mean\n",
        "test_set['Study/Job Satisfaction'] = test_set['Study/Job Satisfaction'].fillna(train_set['Study/Job Satisfaction'].mean())\n",
        "\n",
        "test_set['Study Satisfaction'] = test_set['Study Satisfaction'] / 5\n",
        "test_set['Study Satisfaction'] = test_set['Study Satisfaction'].fillna(0)\n",
        "\n",
        "test_set['Job Satisfaction'] = test_set['Job Satisfaction'] / 5\n",
        "test_set['Job Satisfaction'] = test_set['Job Satisfaction'].fillna(0)\n",
        "\n",
        "test_set['Degree'] = test_set['Degree'].fillna('X')\n",
        "test_set['Degree_freq'] = test_set['Degree'].map(train_set['Degree'].value_counts()) # frequency encoding\n",
        "test_set = pd.get_dummies(test_set, columns=['Degree'])\n",
        "\n",
        "test_set['Have you ever had suicidal thoughts ?'] = test_set['Have you ever had suicidal thoughts ?'].map({'Yes' : 1, 'No' : 0}) #Always trasnforming 2 option object types into binary\n",
        "\n",
        "test_set['Work/Study Hours'] = test_set['Work/Study Hours'] / 24 #Normalized by the Max value\n",
        "\n",
        "test_set['Financial Stress'] = test_set['Financial Stress'] / 5 #Normalized by the Max value\n",
        "test_set['Financial Stress'] = test_set['Financial Stress'].fillna(0)\n",
        "\n",
        "test_set['Family History of Mental Illness'] = test_set['Family History of Mental Illness'].map({'Yes' : 1, 'No' : 0}) #Always trasnforming 2 option object types into binary"
      ],
      "metadata": {
        "id": "PDsjjkSqUs5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_set['Sleep Duration'] = test_set['Sleep Duration'].map(sleep_mapping)\n",
        "test_set['Sleep_Duration_Encoded'] = test_set['Sleep Duration'].apply(encode_sleep_duration)\n",
        "\n",
        "# Apply the function to create 'From' and 'To' columns\n",
        "test_set[['From', 'To']] = test_set['Sleep Duration'].apply(lambda x: pd.Series(extract_range(x)))\n",
        "\n",
        "# Handle missing values\n",
        "test_set['From'] = test_set['From'].fillna(test_set['From'].mean())\n",
        "test_set['To'] = test_set['To'].fillna(test_set['To'].mean())\n",
        "\n",
        "# Drop the original column if not needed\n",
        "test_set.drop(columns=['Sleep Duration'], inplace=True)"
      ],
      "metadata": {
        "id": "1HbcS1vEpXhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set['Dietary Habits'] = test_set['Dietary Habits'].map(dietary_mapping)\n",
        "test_set['Dietary Habits'] = test_set['Dietary Habits'].fillna('X')\n",
        "test_set['Dietary Habits_freq'] = test_set['Dietary Habits'].map(train_set['Dietary Habits'].value_counts()) # frequency encoding\n",
        "test_set = pd.get_dummies(test_set, columns=['Dietary Habits']) # dummy variables"
      ],
      "metadata": {
        "id": "hEEk5lwNji7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_zJpYJuoDPF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "feature_importances = model.feature_importances_\n",
        "important_features = X.columns[feature_importances > 0.005]\n",
        "X_reduced = X[important_features]\n",
        "X_reduced.columns"
      ],
      "metadata": {
        "id": "Pg8iMQDb-1TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=5)\n",
        "X_reduced = pca.fit_transform(X)\n",
        "\n",
        "X_reduced_df = pd.DataFrame(X_reduced, columns=[f'PC{i+1}' for i in range(X_reduced.shape[1])])\n",
        "\n",
        "# Get explained variance ratio\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "# Display the cumulative variance\n",
        "cumulative_variance = explained_variance.cumsum()\n",
        "\n",
        "# Print explained variance and cumulative variance\n",
        "for i, var in enumerate(explained_variance):\n",
        "    print(f\"Principal Component {i+1}: {var:.4f} (Cumulative: {cumulative_variance[i]:.4f})\")"
      ],
      "metadata": {
        "id": "lvXWn4KODndz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Lasso(alpha=0.01)\n",
        "model.fit(X, y)\n",
        "important_features = X.columns[model.coef_ != 0]\n",
        "X_reduced = X[important_features]\n",
        "X_reduced.columns"
      ],
      "metadata": {
        "id": "3o8ts_k9DzgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_set[['City_freq', 'Profession_freq',\n",
        "       'Profession_Teacher', 'Degree_freq', 'Dietary Habits_freq',\n",
        "       'Dietary Habits_Unhealthy', 'Age', 'Academic Pressure', 'Work Pressure', 'Study Satisfaction',\n",
        "       'Job Satisfaction', 'Have you ever had suicidal thoughts ?',\n",
        "       'Work/Study Hours', 'Financial Stress',\n",
        "       'Profession_Architect', 'Profession_Chemist',\n",
        "       'Profession_Content Writer', 'Profession_Entrepreneur',\n",
        "       'Profession_Judge', 'Profession_Pharmacist', 'Academic/Work Pressure',\n",
        "       'Study/Job Satisfaction', 'From', 'To',\n",
        "       'Dietary Habits_Healthy']] + X_reduced_df[['PC1', 'PC2', 'PC3', 'PC4', 'PC5']]"
      ],
      "metadata": {
        "id": "h6pmG59kFa7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_set.copy()\n",
        "y = X['Depression']\n",
        "X = X.drop(columns=['Depression'])\n",
        "\n",
        "# Initial split for training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
        "\n",
        "# Print the count of True and False in both train and validation sets\n",
        "print(\"Training set class distribution:\\n\", y_train.value_counts())\n",
        "print(\"Validation set class distribution:\\n\", y_val.value_counts())"
      ],
      "metadata": {
        "id": "YzZnoXOIGbOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameter search space\n",
        "search_spaces = {\n",
        "    'learning_rate': Real(0.001, 0.5, 'uniform'),\n",
        "    'max_depth': Integer(2, 70),\n",
        "    'n_estimators': Integer(100, 500),\n",
        "    'subsample': Real(0.5, 1.0, 'uniform'),\n",
        "    'colsample_bytree': Real(0.5, 1.0, 'uniform'),\n",
        "    'gamma': Real(0, 10, 'uniform'),\n",
        "    'reg_alpha': Real(0, 10, 'uniform'),\n",
        "    'reg_lambda': Real(0, 10, 'uniform')\n",
        "}\n",
        "\n",
        "# Initialize the XGBClassifier model with GPU support\n",
        "model = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',  # Use for binary classification\n",
        "    tree_method='hist',  # Use GPU for training\n",
        "    verbosity=2\n",
        ")\n",
        "\n",
        "kf = KFold(n_splits=5)  # 5-fold cross-validation\n",
        "\n",
        "# Use 'accuracy' as the scoring metric\n",
        "optimizer = BayesSearchCV(\n",
        "    estimator=model,\n",
        "    search_spaces=search_spaces,\n",
        "    n_iter=64,\n",
        "    cv=kf,\n",
        "    scoring='accuracy',  # Change scoring metric to accuracy\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Fit the optimizer using X_train and y_train\n",
        "optimizer.fit(X_train, y_train)\n",
        "\n",
        "# Get cross-validation results\n",
        "cv_results = optimizer.cv_results_\n",
        "\n",
        "# Create a DataFrame to sort and filter the best models\n",
        "results_df = pd.DataFrame(cv_results)\n",
        "top_15_results = results_df.nlargest(15, 'mean_test_score')  # Get top 5 models by mean test score\n",
        "\n",
        "# Train each of the top 5 models on the full training data and save them\n",
        "top_15_models = []\n",
        "for i, row in top_15_results.iterrows():\n",
        "    params = row['params']\n",
        "    model = xgb.XGBClassifier(\n",
        "        objective='binary:logistic',\n",
        "        tree_method='hist',\n",
        "        **params\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "    top_15_models.append(model)\n",
        "\n",
        "# Print parameters and scores for the top 5 models\n",
        "for idx, model in enumerate(top_15_models):\n",
        "    print(f\"Model {idx + 1} parameters: {top_15_results.iloc[idx]['params']}\")\n",
        "    print(f\"Model {idx + 1} CV score: {top_15_results.iloc[idx]['mean_test_score']}\")\n",
        "\n",
        "print(\"Top 5 XGBoost models based on accuracy have been trained and saved.\")\n"
      ],
      "metadata": {
        "id": "afVvwGfYG4nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import xgboost as xgb\n",
        "\n",
        "# Define the model with the provided parameters\n",
        "xgb_model1 = xgb.XGBClassifier(\n",
        "    colsample_bytree=1.0,\n",
        "    gamma=5.123199546902525,\n",
        "    learning_rate=0.3276877153423676,\n",
        "    max_depth=2,\n",
        "    n_estimators=213,\n",
        "    reg_alpha=0.3658930225724413,\n",
        "    reg_lambda=0.0,\n",
        "    subsample=0.5220163164212284,\n",
        "    eval_metric='error'  # Correct eval_metric for classification\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "xgb_model1.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on train set\n",
        "y_pred_prob_XGB1_train = xgb_model1.predict(X_train)\n",
        "print(\"Classification Report - Train:\")\n",
        "print(classification_report(y_train, y_pred_prob_XGB1_train))\n",
        "\n",
        "# Predictions on validation set\n",
        "y_pred_prob_XGB1_val = xgb_model1.predict(X_val)\n",
        "print(\"Classification Report - Validation:\")\n",
        "print(classification_report(y_val, y_pred_prob_XGB1_val))\n",
        "\n"
      ],
      "metadata": {
        "id": "7PlDkzo6JPrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Get feature importances\n",
        "feature_importance = xgb_model1.feature_importances_\n",
        "\n",
        "# Convert to a DataFrame for easier filtering and visualization\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_importance\n",
        "})\n",
        "\n",
        "# Filter to keep only features with non-zero importance\n",
        "important_features = feature_importance_df[feature_importance_df['Importance'] > 0]\n",
        "\n",
        "# Sort features by importance for better visualization\n",
        "important_features = important_features.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot the remaining important features\n",
        "plt.figure(figsize=(10, 12))\n",
        "plt.barh(important_features['Feature'], important_features['Importance'])\n",
        "plt.title(\"Feature Importance (Non-Zero Only)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display the most important at the top\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kd7q1DHQMmyp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}